{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fd4109-b555-46c7-a272-ab668da92fe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5792185f-2bed-4124-8ba8-8947a11a9de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹 ./model 已存在\n",
      "文件夹 ./tensor 已存在\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import djwtool\n",
    "\n",
    "Config = {\n",
    "    'device': \"torch.device('cuda' if torch.cuda.is_available() else 'cpu')\",\n",
    "    'csv_file_path': 'data/test_right.csv',\n",
    "    'label_column': '微博主分类标注',\n",
    "\n",
    "    'Vectorizer_max_length': 140,\n",
    "    'Vectorizer_model_name': 'hfl/chinese-roberta-wwm-ext-large',\n",
    "\n",
    "    'train_ratio': 0.6,\n",
    "    'val_ratio': 0.2,\n",
    "    'batch_size': 64,\n",
    "\n",
    "    'epochs': 10,\n",
    "    'model_save_path': 'test_right_model.pth'\n",
    "}\n",
    "\n",
    "\n",
    "folders_to_create = ['./model', './tensor']\n",
    "for folder in folders_to_create:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    else:\n",
    "        print(f'文件夹 {folder} 已存在')\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df2326-24fe-4081-b43d-53c957a4a71a",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa04f717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'超话粉丝大咖': 0, '公务员': 1, '大V名人': 2, '党委': 3, '基层组织': 4, '政府': 5, '媒体': 6, '企事业单位': 7, '赛事活动': 8, '社会组织': 9, '社区组织': 10, '司法机关': 11, '网民': 12, '学校': 13, '演艺娱乐明星': 14}\n",
      "15\n",
      "text:\n",
      "0        金V/000274/000320/013621/超话粉丝大咖（朱正廷超话）000000000...\n",
      "1        无V/000857/012365/013157/超话粉丝大咖（陈立农超话）000000000...\n",
      "2        金V/000749/000241/002130/超话粉丝大咖（周杰伦超话）000000000...\n",
      "3        金V/000412/000948/048019/超话粉丝大咖（陈伟霆超话）000000000...\n",
      "4        无V/000516/000885/013115/超话粉丝大咖（宋茜超话）0000000000...\n",
      "                               ...                        \n",
      "12081    无V/000458/005589/003409/著名电影、电视剧观众。00000000000...\n",
      "12082    金V/000775/127134427/010903/女主持人000000000000000...\n",
      "12083    无V/000200/008303/000135/8。23。24000000000000000...\n",
      "12084    蓝V/000107/048572/001365/庐山西海国家级风景名胜区官方微博000000...\n",
      "12085    无V/000145/101107/000601/稀捍行动官方微博00000000000000...\n",
      "Name: text, Length: 10906, dtype: object\n",
      "====================================================================================================\n",
      "input_ids_tensor: torch.Size([10906, 140])\n",
      "attention_mask_tensor: torch.Size([10906, 140])\n",
      "label_tensor: torch.Size([10906])\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "csv = djwtool.CSVProcessor(Config['csv_file_path'])\n",
    "# csv.df = csv.df[csv.df['微博主分类标注'].isin(['网民', '自媒体'])]\n",
    "values= ['网民', '自媒体', '大V名人']\n",
    "csv.df = csv.df[csv.df['微博主分类标注'].isin(values)]\n",
    "label_mapping = csv.generate_label_mapping(Config['label_column'])\n",
    "print(label_mapping)\n",
    "csv.label_numerization(label_mapping, Config['label_column'])  \n",
    "num_classes=len(label_mapping)\n",
    "print(num_classes)\n",
    "\n",
    "column_names = ['关注', '粉丝', '微博']\n",
    "for column_name in column_names:\n",
    "    csv.df[column_name] = csv.df[column_name].apply(lambda x: f'{int(x):06}' if pd.notnull(x) else '000000')\n",
    "csv.fill_nan_with_value()\n",
    "csv.df['认证'] = csv.df['认证'].replace('无', '无V')\n",
    "\n",
    "csv.str_length_normalization('博主标记',26)\n",
    "csv.str_length_normalization('简介',50)\n",
    "csv.str_length_normalization('工作信息',12)\n",
    "csv.str_length_normalization('标签和其他',25)\n",
    "\n",
    "all_to_merge = ['认证', '关注', '粉丝', '微博','博主标记', '简介', '工作信息', '标签和其他']\n",
    "# all_to_merge = ['认证', '昵称']\n",
    "csv.df['text'] = csv.apply_merge_to_columns(all_to_merge)\n",
    "\n",
    "text_column = csv.df['text']\n",
    "print('text:')\n",
    "print(text_column)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "tokenizer = djwtool.TextTokenizer(Config['Vectorizer_model_name'],\n",
    "                                Config['Vectorizer_max_length'])\n",
    "input_ids_list, attention_mask_list = tokenizer.tokenize_dataframe(csv.df['text'])\n",
    "label_list = list(csv.df['label_num'])\n",
    "input_ids_tensor = torch.tensor(input_ids_list)\n",
    "attention_mask_tensor = torch.tensor(attention_mask_list)\n",
    "label_tensor = torch.tensor(label_list)\n",
    "print('input_ids_tensor:',input_ids_tensor.shape)\n",
    "print('attention_mask_tensor:',attention_mask_tensor.shape)\n",
    "print('label_tensor:',label_tensor.shape)\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbcddd-d8e2-4a57-9156-2dd62904b147",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a164c39-3bb0-4b6d-a1ed-fe289c565f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader检查:\n",
      "Batch 1:\n",
      "ids shape: torch.Size([64, 140])\n",
      "attention_mask shape: torch.Size([64, 140])\n",
      "Target shape: torch.Size([64])\n",
      "====================================================================================================\n",
      "训练过程:\n",
      "Epoch [1/10] Train Loss: 0.953258 Train Acc: 0.73 Val Loss: 0.331646 Val Acc: 0.91 Learning Rate: 0.010000\n",
      "\tTime: 00:59\n",
      "Epoch [2/10] Train Loss: 0.251863 Train Acc: 0.93 Val Loss: 0.236498 Val Acc: 0.93 Learning Rate: 0.009910\n",
      "\tTime: 00:59\n",
      "Epoch [3/10] Train Loss: 0.181921 Train Acc: 0.95 Val Loss: 0.228831 Val Acc: 0.95 Learning Rate: 0.009906\n",
      "\tTime: 00:59\n",
      "Epoch [4/10] Train Loss: 0.143619 Train Acc: 0.96 Val Loss: 0.222779 Val Acc: 0.94 Learning Rate: 0.009902\n",
      "\tTime: 00:57\n",
      "Epoch [5/10] Train Loss: 0.119983 Train Acc: 0.97 Val Loss: 0.210463 Val Acc: 0.95 Learning Rate: 0.009903\n",
      "\tTime: 00:59\n",
      "Epoch [6/10] Train Loss: 0.093381 Train Acc: 0.97 Val Loss: 0.238315 Val Acc: 0.94 Learning Rate: 0.009902\n",
      "\tTime: 00:56\n",
      "Epoch [7/10] Train Loss: 0.076391 Train Acc: 0.98 Val Loss: 0.258303 Val Acc: 0.94 Learning Rate: 0.009904\n",
      "\tTime: 00:57\n",
      "Epoch [8/10] Train Loss: 0.065273 Train Acc: 0.98 Val Loss: 0.282234 Val Acc: 0.92 Learning Rate: 0.009903\n",
      "\tTime: 00:57\n",
      "Epoch [9/10] Train Loss: 0.051152 Train Acc: 0.99 Val Loss: 0.279642 Val Acc: 0.94 Learning Rate: 0.009907\n",
      "\tTime: 00:57\n",
      "Epoch [10/10] Train Loss: 0.051054 Train Acc: 0.99 Val Loss: 0.258982 Val Acc: 0.94 Learning Rate: 0.009903\n",
      "\tTime: 00:56\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "td = djwtool.TrainDataset(input_ids_tensor, attention_mask_tensor, label_tensor)\n",
    "train_loader, val_loader, test_loader = td.prepare_dataloaders(Config['train_ratio'],                                                                                                                     \n",
    "                                                               Config['val_ratio'],\n",
    "                                                               Config['batch_size']\n",
    "                                                               )\n",
    "\n",
    "print('train_loader检查:')\n",
    "for batch_idx, (ids, attention_mask , target) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(\"ids shape:\", ids.shape)\n",
    "    print(\"attention_mask shape:\", attention_mask.shape)\n",
    "    print(\"Target shape:\", target.shape)\n",
    "\n",
    "    if batch_idx == 0:  \n",
    "        break\n",
    "print(\"=\" * 100)\n",
    "\n",
    "\n",
    "model = djwtool.BERTVectorizer(Config['Vectorizer_model_name'],num_classes) \n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-2,  weight_decay=5e-4)\n",
    "# optimizer=optim.RMSprop(model.parameters(),lr=0.001,alpha=0.99,momentum=0,weight_decay=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5, weight_decay=5e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, Config['epochs'])\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,  'min',\n",
    "#                                                     factor=0.5, #学习率下降的因子factor=0.5, \n",
    "#                                                     verbose=True,#每次更新都会打印一条消息 \n",
    "#                                                     patience=2,#有2个epochs的平均损失没有变化，学习率将\n",
    "#                                                     min_lr=0.00000001,# 学习率的下限\n",
    "#                                                     threshold=0.001)#小于这个数表示平均损失没有下降\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[75, 150], gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=15, T_mult=2, eta_min=0.00001, last_epoch=-1 , verbose=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print('训练过程:')\n",
    "trainer = djwtool.Trainer(model, train_loader, val_loader,optimizer,\n",
    "                          criterion, scheduler, Config['epochs'], Config['model_save_path'])\n",
    "trainer.train()\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc3878-c924-4a1d-b268-133baf56c78c",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f4c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型测试:\n",
      "Accuracy of the network on the test items: 95.05 %\n",
      "Accuracy of 超话粉丝大咖 : 99.48 %\n",
      "Accuracy of   公务员 : 78.57 %\n",
      "Accuracy of  大V名人 : 97.77 %\n",
      "Accuracy of    党委 : 96.07 %\n",
      "Accuracy of  基层组织 : 92.59 %\n",
      "Accuracy of    政府 : 95.45 %\n",
      "Accuracy of    媒体 : 90.50 %\n",
      "Accuracy of 企事业单位 : 93.44 %\n",
      "Accuracy of  赛事活动 : 94.59 %\n",
      "Accuracy of  社会组织 : 93.55 %\n",
      "Accuracy of  社区组织 : 93.12 %\n",
      "Accuracy of  司法机关 : 99.43 %\n",
      "Accuracy of    网民 : 93.44 %\n",
      "Accuracy of    学校 : 95.61 %\n",
      "Accuracy of 演艺娱乐明星 : 100.00 %\n"
     ]
    }
   ],
   "source": [
    "print('模型测试:')\n",
    "\n",
    "evaluator = djwtool.ModelEvaluator(model, test_loader, label_mapping)\n",
    "evaluator.test_accuracy()\n",
    "evaluator.accuracy_of_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e6d331-d5ff-42a2-9af7-43a7197d149f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m y_true \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     45\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.2\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mModelEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mcalculate_metrics()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mModelEvaluator.__init__\u001b[0;34m(self, y_true, y_pred_prob, threshold)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred_prob \u001b[38;5;241m=\u001b[39m y_pred_prob\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_pred_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, y_true, y_pred_prob, threshold=0.5):\n",
    "        self.y_true = y_true\n",
    "        self.y_pred_prob = y_pred_prob\n",
    "        self.threshold = threshold\n",
    "        self.y_pred = (self.y_pred_prob >= self.threshold).astype(int)\n",
    "\n",
    "    def calculate_metrics(self):\n",
    "        accuracy = accuracy_score(self.y_true, self.y_pred)\n",
    "        precision = precision_score(self.y_true, self.y_pred)\n",
    "        recall = recall_score(self.y_true, self.y_pred)\n",
    "        f1 = f1_score(self.y_true, self.y_pred)\n",
    "        auc = roc_auc_score(self.y_true, self.y_pred_prob)\n",
    "        confusion = confusion_matrix(self.y_true, self.y_pred)\n",
    "        class_report = classification_report(self.y_true, self.y_pred)\n",
    "\n",
    "        return {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'AUC': auc,\n",
    "            'Confusion Matrix': confusion,\n",
    "            'Classification Report': class_report\n",
    "        }\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        fpr, tpr, _ = roc_curve(self.y_true, self.y_pred_prob)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_score(self.y_true, self.y_pred_prob))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "y_true = [1, 0, 1, 1, 0, 0, 1, 0]\n",
    "y_pred_prob = [0.8, 0.6, 0.9, 0.7, 0.3, 0.4, 0.6, 0.2]\n",
    "\n",
    "evaluator = ModelEvaluator(y_true, y_pred_prob)\n",
    "metrics = evaluator.calculate_metrics()\n",
    "print(metrics)\n",
    "\n",
    "evaluator.plot_roc_curve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8244e81-b35d-4617-a0d5-8f568881b28b",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4811b4-677b-4dfe-a836-0a1e07553472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hawk/Documents/internship/8.23/djwtool.py:14: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df= pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:\n",
      "1190     无V/000103/000238/000247/无000000000000000000000...\n",
      "1191     无V/000492/001472/001755/无000000000000000000000...\n",
      "1192     无V/000422/000388/004231/无000000000000000000000...\n",
      "1193     无V/001051/000792/015672/交流、学习、进步！0000000000000...\n",
      "1194     无V/001027/000885/001504/无000000000000000000000...\n",
      "                               ...                        \n",
      "84303    金V/000440/001052/001128/无000000000000000000000...\n",
      "84304    金V/000387/011607/000915/无000000000000000000000...\n",
      "84305    金V/000123/010828/000410/无000000000000000000000...\n",
      "84306    金V/000066/101477/000251/无000000000000000000000...\n",
      "84307    金V/000093/053154/000059/无000000000000000000000...\n",
      "Name: text, Length: 83003, dtype: object\n",
      "====================================================================================================\n",
      "input_ids_tensor: torch.Size([83003, 140])\n",
      "attention_mask_tensor: torch.Size([83003, 140])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import djwtool\n",
    "\n",
    "\n",
    "Config_pdc = {\n",
    "\n",
    "    'device': \"torch.device('cuda' if torch.cuda.is_available() else 'cpu')\",\n",
    "    'csv_file_path': 'pcd.csv',\n",
    "    'num_classes': 2,\n",
    "    'model_path': 'model/model.pth',\n",
    "    'batch_size': 64,\n",
    "    'Vectorizer_max_length': 140,\n",
    "    'Vectorizer_model_name': 'hfl/chinese-roberta-wwm-ext-large'\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "csv = djwtool.CSVProcessor(Config_pdc['csv_file_path'])\n",
    "values= ['网民', '自媒体', '大V名人']\n",
    "csv.df = csv.df[csv.df['微博主分类标注'].isin(values)]\n",
    "\n",
    "column_names = ['关注', '粉丝', '微博']\n",
    "for column_name in column_names:\n",
    "    csv.df[column_name] = csv.df[column_name].apply(lambda x: f'{int(x):06}' if pd.notnull(x) else '000000')\n",
    "csv.fill_nan_with_value()\n",
    "csv.df['认证'] = csv.df['认证'].replace('无', '无V')\n",
    "\n",
    "csv.str_length_normalization('博主标记',26)\n",
    "csv.str_length_normalization('简介',50)\n",
    "csv.str_length_normalization('工作信息',12)\n",
    "csv.str_length_normalization('标签和其他',25)\n",
    "\n",
    "all_to_merge = ['认证', '关注', '粉丝', '微博','博主标记', '简介', '工作信息', '标签和其他']\n",
    "# all_to_merge = ['认证', '昵称']\n",
    "csv.df['text'] = csv.apply_merge_to_columns(all_to_merge)\n",
    "\n",
    "text_column = csv.df['text']\n",
    "print('text:')\n",
    "print(text_column)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "tokenizer = djwtool.TextTokenizer(Config_pdc['Vectorizer_model_name'],\n",
    "                                Config_pdc['Vectorizer_max_length'])\n",
    "input_ids_list, attention_mask_list = tokenizer.tokenize_dataframe(csv.df['text'])\n",
    "input_ids_tensor = torch.tensor(input_ids_list)\n",
    "attention_mask_tensor = torch.tensor(attention_mask_list)\n",
    "\n",
    "print('input_ids_tensor:',input_ids_tensor.shape)\n",
    "print('attention_mask_tensor:',attention_mask_tensor.shape)\n",
    "model_pdc = djwtool.BERTVectorizer(Config_pdc['Vectorizer_model_name'],Config_pdc['num_classes']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0c9af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m pdc_dataset \u001b[38;5;241m=\u001b[39m djwtool\u001b[38;5;241m.\u001b[39mPredictionDataset(input_ids_tensor, attention_mask_tensor)\n\u001b[1;32m      2\u001b[0m pdc_dataloader \u001b[38;5;241m=\u001b[39m pdc_dataset\u001b[38;5;241m.\u001b[39mprepare_dataloader(\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m djwtool\u001b[38;5;241m.\u001b[39mPrediction(model_pdc, Config_pdc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m pdc_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m pdc_list \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpredict(pdc_dataloader)\n",
      "File \u001b[0;32m~/Documents/internship/8.23/djwtool.py:348\u001b[0m, in \u001b[0;36mPrediction.__init__\u001b[0;34m(self, model, model_path)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path))\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/inter/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/inter/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/inter/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/model.pth'"
     ]
    }
   ],
   "source": [
    "pdc_dataset = djwtool.PredictionDataset(input_ids_tensor, attention_mask_tensor)\n",
    "pdc_dataloader = pdc_dataset.prepare_dataloader(64)\n",
    "\n",
    "result = djwtool.Prediction(model_pdc, Config_pdc['model_path'])\n",
    "pdc_list = []\n",
    "pdc_list = result.predict(pdc_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba05fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
