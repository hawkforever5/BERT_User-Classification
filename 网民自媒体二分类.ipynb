{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fd4109-b555-46c7-a272-ab668da92fe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5792185f-2bed-4124-8ba8-8947a11a9de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹 ./model 已存在\n",
      "文件夹 ./tensor 已存在\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import djwtool\n",
    "\n",
    "Config = {\n",
    "    'device': \"torch.device('cuda' if torch.cuda.is_available() else 'cpu')\",\n",
    "    'csv_file_path': 'pcd.csv',\n",
    "    'label_column': '微博主分类标注',\n",
    "\n",
    "    'Vectorizer_max_length': 140,\n",
    "    'Vectorizer_model_name': 'hfl/chinese-roberta-wwm-ext-large',\n",
    "\n",
    "    'train_ratio': 0.6,\n",
    "    'val_ratio': 0.2,\n",
    "    'batch_size': 64,\n",
    "\n",
    "    'epochs': 3,\n",
    "    'model_save_path': 'test_right_model.pth'\n",
    "}\n",
    "\n",
    "\n",
    "folders_to_create = ['./model', './tensor']\n",
    "for folder in folders_to_create:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    else:\n",
    "        print(f'文件夹 {folder} 已存在')\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df2326-24fe-4081-b43d-53c957a4a71a",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa04f717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/three/djwtool.py:14: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df= pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'网民': 0, '自媒体': 1}\n",
      "2\n",
      "text:\n",
      "1190     无V/000103/000238/000247/无000000000000000000000...\n",
      "1191     无V/000492/001472/001755/无000000000000000000000...\n",
      "1192     无V/000422/000388/004231/无000000000000000000000...\n",
      "1193     无V/001051/000792/015672/交流、学习、进步！0000000000000...\n",
      "1194     无V/001027/000885/001504/无000000000000000000000...\n",
      "                               ...                        \n",
      "84303    金V/000440/001052/001128/无000000000000000000000...\n",
      "84304    金V/000387/011607/000915/无000000000000000000000...\n",
      "84305    金V/000123/010828/000410/无000000000000000000000...\n",
      "84306    金V/000066/101477/000251/无000000000000000000000...\n",
      "84307    金V/000093/053154/000059/无000000000000000000000...\n",
      "Name: text, Length: 83003, dtype: object\n",
      "====================================================================================================\n",
      "input_ids_tensor: torch.Size([83003, 140])\n",
      "attention_mask_tensor: torch.Size([83003, 140])\n",
      "label_tensor: torch.Size([83003])\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "csv = djwtool.CSVProcessor(Config['csv_file_path'])\n",
    "# csv.df = csv.df[csv.df['微博主分类标注'].isin(['网民', '自媒体'])]\n",
    "values= ['网民', '自媒体']\n",
    "csv.df = csv.df[csv.df['微博主分类标注'].isin(values)]\n",
    "label_mapping = csv.generate_label_mapping(Config['label_column'])\n",
    "print(label_mapping)\n",
    "csv.label_numerization(label_mapping, Config['label_column'])  \n",
    "num_classes=len(label_mapping)\n",
    "print(num_classes)\n",
    "\n",
    "column_names = ['关注', '粉丝', '微博']\n",
    "for column_name in column_names:\n",
    "    csv.df[column_name] = csv.df[column_name].apply(lambda x: f'{int(x):06}' if pd.notnull(x) else '000000')\n",
    "csv.fill_nan_with_value()\n",
    "csv.df['认证'] = csv.df['认证'].replace('无', '无V')\n",
    "\n",
    "csv.str_length_normalization('博主标记',26)\n",
    "csv.str_length_normalization('简介',50)\n",
    "csv.str_length_normalization('工作信息',12)\n",
    "csv.str_length_normalization('标签和其他',25)\n",
    "\n",
    "all_to_merge = ['认证', '关注', '粉丝', '微博','博主标记', '简介', '工作信息', '标签和其他']\n",
    "# all_to_merge = ['认证', '昵称']\n",
    "csv.df['text'] = csv.apply_merge_to_columns(all_to_merge)\n",
    "\n",
    "text_column = csv.df['text']\n",
    "print('text:')\n",
    "print(text_column)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "tokenizer = djwtool.TextTokenizer(Config['Vectorizer_model_name'],\n",
    "                                Config['Vectorizer_max_length'])\n",
    "input_ids_list, attention_mask_list = tokenizer.tokenize_dataframe(csv.df['text'])\n",
    "label_list = list(csv.df['label_num'])\n",
    "input_ids_tensor = torch.tensor(input_ids_list)\n",
    "attention_mask_tensor = torch.tensor(attention_mask_list)\n",
    "label_tensor = torch.tensor(label_list)\n",
    "print('input_ids_tensor:',input_ids_tensor.shape)\n",
    "print('attention_mask_tensor:',attention_mask_tensor.shape)\n",
    "print('label_tensor:',label_tensor.shape)\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbcddd-d8e2-4a57-9156-2dd62904b147",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a164c39-3bb0-4b6d-a1ed-fe289c565f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader检查:\n",
      "Batch 1:\n",
      "ids shape: torch.Size([64, 140])\n",
      "attention_mask shape: torch.Size([64, 140])\n",
      "Target shape: torch.Size([64])\n",
      "====================================================================================================\n",
      "训练过程:\n",
      "Epoch [1/3] Train Loss: 0.050892 Train Acc: 0.98 Val Loss: 0.037965 Val Acc: 0.98 Learning Rate: 0.010000\n",
      "\tTime: 07:14\n",
      "Epoch [2/3] Train Loss: 0.034015 Train Acc: 0.98 Val Loss: 0.039522 Val Acc: 0.98 Learning Rate: 0.009894\n",
      "\tTime: 07:14\n",
      "Epoch [3/3] Train Loss: 0.031325 Train Acc: 0.99 Val Loss: 0.031048 Val Acc: 0.98 Learning Rate: 0.009894\n",
      "\tTime: 07:14\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "td = djwtool.TrainDataset(input_ids_tensor, attention_mask_tensor, label_tensor)\n",
    "train_loader, val_loader, test_loader = td.prepare_dataloaders(Config['train_ratio'],                                                                                                                     \n",
    "                                                               Config['val_ratio'],\n",
    "                                                               Config['batch_size']\n",
    "                                                               )\n",
    "\n",
    "print('train_loader检查:')\n",
    "for batch_idx, (ids, attention_mask , target) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(\"ids shape:\", ids.shape)\n",
    "    print(\"attention_mask shape:\", attention_mask.shape)\n",
    "    print(\"Target shape:\", target.shape)\n",
    "\n",
    "    if batch_idx == 0:  \n",
    "        break\n",
    "print(\"=\" * 100)\n",
    "\n",
    "\n",
    "model = djwtool.BERTVectorizer(Config['Vectorizer_model_name'],num_classes) \n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-2,  weight_decay=5e-4)\n",
    "# optimizer=optim.RMSprop(model.parameters(),lr=0.001,alpha=0.99,momentum=0,weight_decay=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5, weight_decay=5e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, Config['epochs'])\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,  'min',\n",
    "#                                                     factor=0.5, #学习率下降的因子factor=0.5, \n",
    "#                                                     verbose=True,#每次更新都会打印一条消息 \n",
    "#                                                     patience=2,#有2个epochs的平均损失没有变化，学习率将\n",
    "#                                                     min_lr=0.00000001,# 学习率的下限\n",
    "#                                                     threshold=0.001)#小于这个数表示平均损失没有下降\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[75, 150], gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=15, T_mult=2, eta_min=0.00001, last_epoch=-1 , verbose=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print('训练过程:')\n",
    "trainer = djwtool.Trainer(model, train_loader, val_loader,optimizer,\n",
    "                          criterion, scheduler, Config['epochs'], Config['model_save_path'])\n",
    "trainer.train()\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc3878-c924-4a1d-b268-133baf56c78c",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f4c939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型测试:\n",
      "Accuracy of the network on the test items: 98.66 %\n",
      "Accuracy of    网民 : 99.10 %\n",
      "Accuracy of   自媒体 : 89.00 %\n"
     ]
    }
   ],
   "source": [
    "print('模型测试:')\n",
    "\n",
    "evaluator = djwtool.ModelEvaluator(model, test_loader, label_mapping)\n",
    "evaluator.test_accuracy()\n",
    "evaluator.accuracy_of_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6d331-d5ff-42a2-9af7-43a7197d149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# class ModelEvaluator:\n",
    "#     def __init__(self, y_true, y_pred_prob, threshold=0.5):\n",
    "#         self.y_true = y_true\n",
    "#         self.y_pred_prob = y_pred_prob\n",
    "#         self.threshold = threshold\n",
    "#         self.y_pred = (self.y_pred_prob >= self.threshold).astype(int)\n",
    "\n",
    "#     def calculate_metrics(self):\n",
    "#         accuracy = accuracy_score(self.y_true, self.y_pred)\n",
    "#         precision = precision_score(self.y_true, self.y_pred)\n",
    "#         recall = recall_score(self.y_true, self.y_pred)\n",
    "#         f1 = f1_score(self.y_true, self.y_pred)\n",
    "#         auc = roc_auc_score(self.y_true, self.y_pred_prob)\n",
    "#         confusion = confusion_matrix(self.y_true, self.y_pred)\n",
    "#         class_report = classification_report(self.y_true, self.y_pred)\n",
    "\n",
    "#         return {\n",
    "#             'Accuracy': accuracy,\n",
    "#             'Precision': precision,\n",
    "#             'Recall': recall,\n",
    "#             'F1 Score': f1,\n",
    "#             'AUC': auc,\n",
    "#             'Confusion Matrix': confusion,\n",
    "#             'Classification Report': class_report\n",
    "#         }\n",
    "\n",
    "#     def plot_roc_curve(self):\n",
    "#         fpr, tpr, _ = roc_curve(self.y_true, self.y_pred_prob)\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_score(self.y_true, self.y_pred_prob))\n",
    "#         plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "#         plt.xlim([0.0, 1.0])\n",
    "#         plt.ylim([0.0, 1.05])\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.title('Receiver Operating Characteristic')\n",
    "#         plt.legend(loc='lower right')\n",
    "#         plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# y_true = [1, 0, 1, 1, 0, 0, 1, 0]\n",
    "# y_pred_prob = [0.8, 0.6, 0.9, 0.7, 0.3, 0.4, 0.6, 0.2]\n",
    "\n",
    "# evaluator = ModelEvaluator(y_true, y_pred_prob)\n",
    "# metrics = evaluator.calculate_metrics()\n",
    "# print(metrics)\n",
    "\n",
    "# evaluator.plot_roc_curve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8244e81-b35d-4617-a0d5-8f568881b28b",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499e2c13-0b5d-4466-96ea-5b7cfd21dea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '网民', 1: '自媒体'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import djwtool\n",
    "import tqdm\n",
    "\n",
    "\n",
    "Config_pdc = {\n",
    "    'device': \"torch.device('cuda' if torch.cuda.is_available() else 'cpu')\",\n",
    "    'csv_file_path': 'pcd.csv',\n",
    "    'num_classes': 2,\n",
    "    'model_save_path': 'model/test_right_model.pth',\n",
    "    'batch_size': 20,\n",
    "    'Vectorizer_max_length': 140,\n",
    "    'Vectorizer_model_name': 'hfl/chinese-roberta-wwm-ext-large'\n",
    "}\n",
    "\n",
    "original_dict = {'网民': 0, '自媒体': 1}\n",
    "reverse_dict = {value: key for key, value in original_dict.items()}\n",
    "print(reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4811b4-677b-4dfe-a836-0a1e07553472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/three/djwtool.py:14: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df= pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83003\n",
      "text:\n",
      "1190     无V/000103/000238/000247/无000000000000000000000...\n",
      "1191     无V/000492/001472/001755/无000000000000000000000...\n",
      "1192     无V/000422/000388/004231/无000000000000000000000...\n",
      "1193     无V/001051/000792/015672/交流、学习、进步！0000000000000...\n",
      "1194     无V/001027/000885/001504/无000000000000000000000...\n",
      "                               ...                        \n",
      "84303    金V/000440/001052/001128/无000000000000000000000...\n",
      "84304    金V/000387/011607/000915/无000000000000000000000...\n",
      "84305    金V/000123/010828/000410/无000000000000000000000...\n",
      "84306    金V/000066/101477/000251/无000000000000000000000...\n",
      "84307    金V/000093/053154/000059/无000000000000000000000...\n",
      "Name: text, Length: 83003, dtype: object\n",
      "83003\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "csv_pdc = djwtool.CSVProcessor(Config_pdc['csv_file_path'])\n",
    "values= ['网民', '自媒体']\n",
    "csv_pdc.df = csv_pdc.df[csv_pdc.df['微博主分类标注'].isin(values)]\n",
    "print(csv_pdc.df.shape[0])\n",
    "\n",
    "column_names = ['关注', '粉丝', '微博']\n",
    "for column_name in column_names:\n",
    "    csv_pdc.df[column_name] = csv_pdc.df[column_name].apply(lambda x: f'{int(x):06}' if pd.notnull(x) else '000000')\n",
    "csv_pdc.fill_nan_with_value()\n",
    "csv_pdc.df['认证'] = csv_pdc.df['认证'].replace('无', '无V')\n",
    "\n",
    "csv_pdc.str_length_normalization('博主标记',26)\n",
    "csv_pdc.str_length_normalization('简介',50)\n",
    "csv_pdc.str_length_normalization('工作信息',12)\n",
    "csv_pdc.str_length_normalization('标签和其他',25)\n",
    "\n",
    "all_to_merge = ['认证', '关注', '粉丝', '微博','博主标记', '简介', '工作信息', '标签和其他']\n",
    "# all_to_merge = ['认证', '昵称']\n",
    "csv_pdc.df['text'] = csv_pdc.apply_merge_to_columns(all_to_merge)\n",
    "\n",
    "text_column = csv_pdc.df['text']\n",
    "print('text:')\n",
    "print(text_column)\n",
    "print(csv_pdc.df.shape[0])\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255c920e-480b-4717-8116-ec4bc3afb037",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids_tensor: torch.Size([83003, 140])\n",
      "attention_mask_tensor: torch.Size([83003, 140])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = djwtool.TextTokenizer(Config_pdc['Vectorizer_model_name'],\n",
    "                                Config_pdc['Vectorizer_max_length'])\n",
    "input_ids_list, attention_mask_list = tokenizer.tokenize_dataframe(csv_pdc.df['text'])\n",
    "input_ids_tensor = torch.tensor(input_ids_list)\n",
    "attention_mask_tensor = torch.tensor(attention_mask_list)\n",
    "\n",
    "print('input_ids_tensor:',input_ids_tensor.shape)\n",
    "print('attention_mask_tensor:',attention_mask_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0c9af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83003\n"
     ]
    }
   ],
   "source": [
    "pdc_dataset = djwtool.PredictionDataset(input_ids_tensor, attention_mask_tensor)\n",
    "pdc_dataloader = pdc_dataset.prepare_dataloader(64)\n",
    "\n",
    "model_pdc = djwtool.BERTVectorizer(Config_pdc['Vectorizer_model_name'],Config_pdc['num_classes']) \n",
    "result = djwtool.Prediction(model_pdc, Config_pdc['model_save_path'])\n",
    "predictions = []\n",
    "predictions = result.predict(pdc_dataloader)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804610e4-5266-488b-a8a7-46213f799269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83003\n"
     ]
    }
   ],
   "source": [
    "predicted_label = [reverse_dict[number] for number in predictions]\n",
    "# print(predicted_label)\n",
    "print(csv_pdc.df.shape[0])\n",
    "csv_pdc.df['pdc'] = predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990a3524-642f-46f7-991e-6454a30740f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal rows ratio: 90.09%\n"
     ]
    }
   ],
   "source": [
    "csv_pdc.df.to_csv('new_dataframe.csv',  encoding='utf_8_sig', index=False)\n",
    "equal_rows = csv_pdc.df[csv_pdc.df['微博主分类标注'] == csv_pdc.df['pdc']]\n",
    "num_equal_rows = len(equal_rows)\n",
    "\n",
    "# 计算比重\n",
    "total_rows = len(csv_pdc.df)\n",
    "equal_rows_ratio = num_equal_rows / total_rows\n",
    "\n",
    "print(f\"Equal rows ratio: {equal_rows_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a82ebc8-42dc-45c7-9430-8d87c5c61efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'网民': 0, '自媒体': 1}\n",
      "2\n",
      "Accuracy for class 0: 0.9392499810983139\n",
      "Accuracy for class 1: 0.939917695473251\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = predictions\n",
    "label_mapping = csv_pdc.generate_label_mapping('微博主分类标注')\n",
    "print(label_mapping)\n",
    "csv_pdc.label_numerization(label_mapping, '微博主分类标注')  \n",
    "num_classes=len(label_mapping)\n",
    "print(num_classes)\n",
    "true_labels = csv_pdc.df['label_num']\n",
    "class_0_predicted = [pred for pred, true in zip(predicted_labels, true_labels) if true == 0]\n",
    "class_1_predicted = [pred for pred, true in zip(predicted_labels, true_labels) if true == 1]\n",
    "\n",
    "# 计算每个类别的准确率\n",
    "accuracy_class_0 = sum([1 for pred, true in zip(class_0_predicted, true_labels) if pred == true]) / len(class_0_predicted)\n",
    "accuracy_class_1 = sum([1 for pred, true in zip(class_1_predicted, true_labels) if pred == true]) / len(class_1_predicted)\n",
    "\n",
    "print(\"Accuracy for class 0:\", accuracy_class_0)\n",
    "print(\"Accuracy for class 1:\", accuracy_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d98ac3a8-1605-4d36-a19b-c523e3ea200e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions for class 1: 3\n"
     ]
    }
   ],
   "source": [
    "# 假设你有模型的预测结果和真实标签\n",
    "predicted_labels = [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
    "true_labels = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "# 统计原始标签为0且被正确预测的数量\n",
    "correct_predictions_for_class_0 = sum([1 for pred, true in zip(predicted_labels, true_labels) if true == 1 and pred == true])\n",
    "\n",
    "print(\"Correct predictions for class 1:\", correct_predictions_for_class_0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
